import logging
import os
import re
from typing import List, Optional

from .schemas import OrchestratorInput, OrchestratorOutput
from . import intent_classifier, local_exec, planner, agent_client  # ì‚¬ìš©ë¨ (Pylance OK)

log = logging.getLogger("orchestrator")
ilog = logging.getLogger("orchestrator.intent")

AGENT_ENABLED = os.getenv("AGENT_ENABLED", "false").lower() == "true"


# =========================
# RAG í•©ì„± ìœ í‹¸
# =========================
def _format_rag_snippets(matches, max_chars=1400, max_items=5) -> str:
    """ì—ì´ì „íŠ¸ê°€ ì¤€ RAG ë§¤ì¹˜ë“¤ì„ ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬"""
    items = (matches or [])[:max_items]
    lines = ["[USAGE GUIDE SNIPPETS]"]
    used = 0
    for i, m in enumerate(items, 1):
        if isinstance(m, str):
            txt, meta, score = m.strip(), {}, None
        else:
            txt = (m.get("text") or "").strip()
            meta = m.get("meta") or {}
            score = m.get("score")
        if not txt:
            continue
        page = meta.get("page")
        head = f"- #{i} (p.{page})" if page else f"- #{i}"
        chunk = f"{head} {txt}"
        if used + len(chunk) > max_chars:
            break
        lines.append(chunk)
        used += len(chunk)
    return "\n".join(lines)


def _synthesize_from_rag(router, cfg, query: str, rag: dict, overrides: dict, usr_name="ê²ŒìŠ¤íŠ¸", usr_snm=""):
    """RAG ìŠ¤ë‹ˆí« + ì‹œìŠ¤í…œ ê·œì¹™ìœ¼ë¡œ ìµœì¢… ë‹µë³€ í•©ì„± (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)"""
    base = local_exec.build_base_messages(cfg, {
        "user_name": usr_name,
        "salutation_prefix": "",
        "user_affiliation": usr_snm or ""
    })
    concise_rule = ((cfg.get("prompts", {}).get("snippets", {}) or {}).get("concise_rule") or "")
    
    # ê°œì„ ëœ í•©ì„± ê·œì¹™ - ë” ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ë˜ëŠ” ë‹µë³€ ìœ ë„
    sys_rule = (
        "ì•„ë˜ ì œê³µëœ ë¬¸ì„œ ìŠ¤ë‹ˆí«ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µí•˜ë¼. "
        "ìŠ¤ë‹ˆí«ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¨ê³„ë³„ ì•ˆë‚´ë‚˜ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œí•˜ë¼. "
        "ìŠ¤ë‹ˆí«ì— ë¶€ë¶„ì  ì •ë³´ë§Œ ìˆë‹¤ë©´, ìˆëŠ” ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ë§Œë“¤ì–´ë¼. "
        "ì™„ì „íˆ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì´ ì•„ë‹Œ ì´ìƒ ì ê·¹ì ìœ¼ë¡œ ì•ˆë‚´í•˜ë¼."
    )
    
    snippets = _format_rag_snippets((rag or {}).get("matches") or [])

    messages = list(base)
    messages.append({"role": "system", "content": sys_rule})
    if snippets:
        messages.append({"role": "system", "content": snippets})
    
    # ì§ˆë¬¸ë³„ ë§ì¶¤ ê°€ì´ë“œ ì¶”ê°€
    query_lower = query.lower()
    if any(keyword in query_lower for keyword in ["íšŒì›ê°€ì…", "ê°€ì…", "ê³„ì •ìƒì„±"]):
        guide = (
            "íšŒì›ê°€ì…ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. ê°€ì… ì ˆì°¨, í•„ìš”í•œ ì •ë³´, ì ‘ê·¼ ê²½ë¡œ ë“±ì„ "
            "ìˆœì„œëŒ€ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. êµ¬ì²´ì ì¸ ë²„íŠ¼ëª…ì´ë‚˜ í˜ì´ì§€ëª…ì´ ìˆë‹¤ë©´ ëª…ì‹œí•˜ì„¸ìš”."
        )
        messages.append({"role": "system", "content": guide})
    elif any(keyword in query_lower for keyword in ["ê°œì¸ì •ë³´", "ì •ë³´ìˆ˜ì •", "í”„ë¡œí•„"]):
        guide = (
            "ê°œì¸ì •ë³´ ê´€ë¦¬ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì •ë³´ ìˆ˜ì • ë°©ë²•, ì ‘ê·¼ ê²½ë¡œ, í•„ìš”í•œ ë‹¨ê³„ë¥¼ "
            "êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•´ì£¼ì„¸ìš”. ê´€ë ¨ ë©”ë‰´ë‚˜ ë²„íŠ¼ ìœ„ì¹˜ë„ í¬í•¨í•˜ì„¸ìš”."
        )
        messages.append({"role": "system", "content": guide})
    elif any(keyword in query_lower for keyword in ["ë¡œê·¸ì¸", "ì¸ì¦"]):
        guide = (
            "ë¡œê·¸ì¸/ì¸ì¦ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. ë¡œê·¸ì¸ ë°©ë²•, ë¬¸ì œ í•´ê²° ë°©ë²•, ê´€ë ¨ ê¸°ëŠ¥ì„ "
            "ë‹¨ê³„ë³„ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        )
        messages.append({"role": "system", "content": guide})
    
    if concise_rule:
        messages.append({"role": "system", "content": concise_rule})
    messages.append({"role": "user", "content": query})

    # ìƒì„± íŒŒë¼ë¯¸í„° ì¡°ì • - ë” í’ë¶€í•œ ë‹µë³€ì„ ìœ„í•´
    ov = local_exec.apply_generation_defaults(cfg, overrides or {})
    ov["max_new_tokens"] = max(ov.get("max_new_tokens", 180), 250)  # ìµœì†Œ 250í† í° ë³´ì¥
    ov["temperature"] = max(ov.get("temperature", 0.7), 0.5)  # ì•½ê°„ì˜ ì°½ì˜ì„± í—ˆìš©
    
    body = router.generate_messages(messages, overrides=ov)
    return local_exec.apply_output_policy(cfg, body)


def _extract_rag_blob(res: dict) -> Optional[dict]:
    """
    ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ RAG ê²°ê³¼ë¥¼ ìµœëŒ€í•œ ê´€ëŒ€í•˜ê²Œ ì°¾ëŠ”ë‹¤.
    ì§€ì› í˜•íƒœ:
      - top-level: {"rag": {...}}, {"context_snippets": [...]}, {"matches":[...]}
      - nested: {"data":{"rag":{...}}}, {"data":{"result":{...}}}, {"result":{...}}, {"tool_result":{...}}
      - Chroma raw: {"documents":[[...]], "metadatas":[[...]], "distances":[[...]]}
    """
    if not isinstance(res, dict):
        return None

    log.info("[RAG_EXTRACT] Processing response with keys: %s", list(res.keys()))

    # 0) context_snippets ë°”ë¡œ ì²˜ë¦¬
    if isinstance(res.get("context_snippets"), list):
        cs = res["context_snippets"]
        matches = []
        for x in cs:
            if isinstance(x, str):
                matches.append({"text": x, "meta": {}, "score": None})
            elif isinstance(x, dict) and ("text" in x or "chunk" in x):
                txt = x.get("text") or x.get("chunk") or ""
                meta = x.get("meta") or {}
                score = x.get("score")
                matches.append({"text": txt, "meta": meta, "score": score})
        if matches:
            log.info("[RAG_EXTRACT] Found %d matches in context_snippets", len(matches))
            return {"matches": matches}

    # 1) ê²½ë¡œ íƒìƒ‰
    cand_paths: List[List[str]] = [
        ["rag"],
        ["data", "rag"],
        ["data", "result"],
        ["result"],
        ["tool_result", "rag"],
        ["tool_result"],
        ["data", "tool_result"],
    ]

    def dig(d: dict, path: List[str]):
        cur = d
        for key in path:
            if not isinstance(cur, dict):
                return None
            cur = cur.get(key)
        return cur

    for p in cand_paths:
        blob = dig(res, p)
        log.info("[RAG_EXTRACT] Checking path %s: %s", p, type(blob).__name__ if blob else "None")
        
        if isinstance(blob, dict):
            if isinstance(blob.get("matches"), list):
                matches = blob["matches"]
                # ë¹ˆ matchesë„ ìœ íš¨í•œ ê²°ê³¼ë¡œ ì²˜ë¦¬ (ê²€ìƒ‰í–ˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ìŒ)
                log.info("[RAG_EXTRACT] Found %d matches in path %s", len(matches), p)
                return {"matches": matches}
            
            # íˆ´ë³„ ê²°ê³¼ ì²˜ë¦¬
            for tool_key, tool_res in blob.items():
                if isinstance(tool_res, dict):
                    if isinstance(tool_res.get("rag"), dict) and isinstance(tool_res["rag"].get("matches"), list):
                        matches = tool_res["rag"]["matches"]
                        log.info("[RAG_EXTRACT] Found %d matches in tool %s", len(matches), tool_key)
                        return {"matches": matches}
            
            docs = blob.get("documents")
            metas = blob.get("metadatas")
            dists = blob.get("distances")
            if isinstance(docs, list) and isinstance(metas, list):
                docs0 = docs[0] if docs and isinstance(docs[0], list) else docs
                metas0 = metas[0] if metas and isinstance(metas[0], list) else metas
                dists0 = dists[0] if dists and isinstance(dists[0], list) else dists
                matches = []
                for i, d in enumerate(docs0):
                    m = metas0[i] if i < len(metas0) else {}
                    s = float(dists0[i]) if dists0 and i < len(dists0) else None
                    matches.append({"text": d, "meta": m, "score": s})
                if matches:
                    log.info("[RAG_EXTRACT] Found %d matches from Chroma format", len(matches))
                    return {"matches": matches}
                    
        if isinstance(blob, list) and blob and isinstance(blob[0], dict) and "text" in blob[0]:
            log.info("[RAG_EXTRACT] Found %d matches in list format", len(blob))
            return {"matches": blob}

    # 2) ìµœí›„ ìˆ˜ë‹¨
    if isinstance(res.get("matches"), list):
        log.info("[RAG_EXTRACT] Found %d matches in top-level matches", len(res["matches"]))
        return {"matches": res["matches"]}

    log.warning("[RAG_EXTRACT] No RAG matches found in response")
    return None


def _extract_final_data(res: dict) -> Optional[dict]:
    """ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ final_data ì¶”ì¶œ"""
    if not isinstance(res, dict):
        return None
    
    # ì§ì ‘ final_dataê°€ ìˆëŠ” ê²½ìš°
    if isinstance(res.get("final_data"), dict):
        return res["final_data"]
    
    # data í•˜ìœ„ì— ìˆëŠ” ê²½ìš°
    if isinstance(res.get("data"), dict) and isinstance(res["data"].get("final_data"), dict):
        return res["data"]["final_data"]
    
    # Oracle ê²°ê³¼: data.result ë˜ëŠ” result
    result_data = res.get("result") or (res.get("data", {}) if isinstance(res.get("data"), dict) else {}).get("result")
    if isinstance(result_data, dict):
        # Oracle ê²°ê³¼ êµ¬ì¡°: {university, year, metric_label, value, ...}
        if "university" in result_data and "value" in result_data:
            return result_data
    
    return None


def _extract_text_response(res: dict) -> Optional[str]:
    """ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶”ì¶œ"""
    if not isinstance(res, dict):
        return None
    
    # í‘œì¤€ í…ìŠ¤íŠ¸ ì‘ë‹µ í‚¤ë“¤
    text_keys = ["final_text", "answer", "text", "message"]
    
    # ìµœìƒìœ„ ë ˆë²¨ ì²´í¬
    for k in text_keys:
        if isinstance(res.get(k), str) and res[k].strip():
            return res[k].strip()
    
    # data í•˜ìœ„ ì²´í¬
    if isinstance(res.get("data"), dict):
        for k in text_keys:
            v = res["data"].get(k)
            if isinstance(v, str) and v.strip():
                return v.strip()
    
    return None


# =========================
# ê·¸ë˜í”„ ê²½ë¡œ ì‚¬ìš© íŒë‹¨
# =========================
_USERLOCAL_FIELD_TOKENS = [
    "ì†Œì†ëŒ€í•™", "ì†Œì† ëŒ€í•™",
    "ìë£Œêµ¬ì…ë¹„", "ìë£Œ êµ¬ì…ë¹„",
    "ì˜ˆì¸¡ì ìˆ˜", "ì ìˆ˜",
    "í•™ë…„", "4í•™ë…„", "3í•™ë…„", "2í•™ë…„", "1í•™ë…„"
]
_PAGE_TOKENS = [
    "í•™ìŠµí™˜ê²½ ë¶„ì„", "ë°œì „ë„ ë¶„ì„", "ë§ˆì´í˜ì´ì§€", "ë‚´ì •ë³´", "ë‚´ ì •ë³´", "ì„¤ì •", "ëŒ€ì‹œë³´ë“œ", "ë©”ë‰´", "í˜ì´ì§€"
]
_AND_TOKENS = [" ê³¼ ", " ì™€ ", " ë° ", " ê·¸ë¦¬ê³  ", " í•˜ê³  ", " ë‘ ", " ì´ë‘ ", ", "]


# ê·¸ë˜í”„ ê²½ë¡œ ì‚¬ìš© íŒë‹¨ ê°œì„ 
def _should_use_graph(query: str) -> bool:
    """
    ê·¸ë˜í”„ ê²½ë¡œë¡œ ë³´ë‚¼ì§€ íŒë‹¨ (ê°•í™”ëœ ë¡œì§):
    - ëª…ì‹œì  ì—°ê²°ì‚¬ + ë³µìˆ˜ ìš”ì†Œ
    - ë¹„êµ/ê³„ì‚° í‚¤ì›Œë“œ
    - ë³µìˆ˜ ëŒ€í•™/ì§€í‘œ ì¡°í•©
    - ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ 2ë¬¸ì¥ ì´ìƒ
    """
    q = (query or "").strip()
    if not q:
        return False

    # 1) ë¬¸ì¥ë¶€í˜¸ ê¸°ì¤€ 2ë¬¸ì¥ ì´ìƒ
    sent_splits = [p for p in re.split(r'(?<=[\?\.\!])\s+', q) if p.strip()]
    if len(sent_splits) >= 2:
        return True

    # 2) ëª…ì‹œì  ì—°ê²°ì‚¬ ì¡´ì¬
    conjunctions = [" ê³¼ ", " ì™€ ", " ë° ", " ê·¸ë¦¬ê³  ", " í•˜ê³  ", " ë‘ ", " ì´ë‘ ", ","]
    has_conjunction = any(conj in q for conj in conjunctions)
    
    # 3) ë³µìˆ˜ ìš”ì†Œ ì¹´ìš´íŠ¸
    # í•™ë…„ ìˆ˜ ì¹´ìš´íŠ¸
    grade_count = len(re.findall(r'([1-4])\s*í•™ë…„', q))
    
    # ëŒ€í•™ ìˆ˜ ì¹´ìš´íŠ¸
    univ_pattern = re.compile(r'([ê°€-í£A-Za-z]+ëŒ€í•™êµ)')
    univs = [m.group(1) for m in univ_pattern.finditer(q)]
    univ_count = len([u for u in univs if u not in ["ì–´ëŠëŒ€í•™êµ", "ë¬´ìŠ¨ëŒ€í•™êµ"]])
    
    # ì§€í‘œ ìˆ˜ ì¹´ìš´íŠ¸
    metrics = ["ì ìˆ˜", "ì˜ˆì¸¡ì ìˆ˜", "ìë£Œêµ¬ì…ë¹„", "êµ¬ì…ë¹„", "ëŒ€ì¶œ", "ë°©ë¬¸"]
    metric_count = sum(1 for metric in metrics if metric in q)
    
    # 4) ë¹„êµ/ê³„ì‚° í‚¤ì›Œë“œ
    comparison_keywords = ["ë¹„êµ", "ì°¨ì´", "ë™ì¼ì—°ë„", "ê°™ì€ í•´", "vs", "ëŒ€ë¹„", "ë”", "ì ê²Œ", "ë§ì´"]
    has_comparison = any(kw in q for kw in comparison_keywords)
    
    # 5) ë³µí•© êµ¬ì¡° íŒë‹¨
    total_elements = grade_count + univ_count + metric_count
    
    # ê·¸ë˜í”„ ê²½ë¡œ ì¡°ê±´ë“¤
    conditions = [
        has_conjunction and total_elements >= 2,    # ì—°ê²°ì‚¬ + ë³µìˆ˜ ìš”ì†Œ
        has_comparison and total_elements >= 1,     # ë¹„êµ í‚¤ì›Œë“œ + ìš”ì†Œ
        univ_count >= 2,                            # ë³µìˆ˜ ëŒ€í•™
        grade_count >= 2,                           # ë³µìˆ˜ í•™ë…„
        metric_count >= 2,                          # ë³µìˆ˜ ì§€í‘œ
        total_elements >= 3,                        # ì „ì²´ ìš”ì†Œ 3ê°œ ì´ìƒ
        len(q) >= 60 and q.count(",") >= 2,        # ê¸´ ë¬¸ì¥ + ì‰¼í‘œ
        # "ë‚´ ê²ƒê³¼ XXëŒ€í•™êµ" íŒ¨í„´
        (any(self_word in q for self_word in ["ë‚´", "ë‚˜ì˜"]) and univ_count >= 1)
    ]
    
    return any(conditions)


def _scale_max_tokens(base_max_new: int, num_units: int, is_agent: bool = False) -> int:
    """
    ë³µí•© ìš”ì²­(ìœ ë‹›/íƒœìŠ¤í¬ ìˆ˜)ì— ë¹„ë¡€í•˜ì—¬ max_new_tokensë¥¼ í™•ëŒ€.
    - ê¸°ë³¸ í™•ëŒ€: +60 * (units-1)
    - ì—ì´ì „íŠ¸ ê²½ë¡œë©´ ìµœì†Œ 320 ë³´ì¥
    - ìƒí•œì„ ì€ 800 (ê³¼ë„í•œ ìƒì„± ë°©ì§€)
    """
    units = max(1, int(num_units))
    scaled = base_max_new + 60 * (units - 1)
    if is_agent:
        scaled = max(320, scaled)
    return min(800, max(120, int(scaled)))


# =========================
# ì§„ì…ì 
# =========================
def handle(router, cfg: dict, repo, inp: OrchestratorInput) -> OrchestratorOutput:
    """
    LangGraph ê¸°ë°˜ ë©€í‹°-ì§ˆë¬¸ ë¶„í•´/ì‹¤í–‰ â†’ ì¡°ë¦½ì„ ìš°ì„  ì‹œë„í•˜ê³ ,
    ì‹¤íŒ¨í•˜ê±°ë‚˜ ë‹¨ë¬¸ì´ë©´ ê¸°ì¡´ ë‹¨ì¼ ë¶„ê¸° ë¡œì§ìœ¼ë¡œ í´ë°±
    """
    # 1) 1ì°¨ ì˜ë„ ë¶„ë¥˜
    intent = intent_classifier.classify(inp.query, inp.usr_id)
    ilog.info(
        "[INTENT] usr_id=%r conv_id=%r kind=%s reason=%s slots=%d calc=%s external=%s",
        inp.usr_id, inp.conv_id,
        intent.kind, intent.reason,
        len(intent.user_slots or []),
        intent.wants_calculation,
        intent.external_entities,
    )

    # 1-1) ğŸ”¸ ì˜¤ë²„ë¼ì´ë“œ ë¡œì§ ìˆ˜ì •: ë³µí•© ì§ˆë¬¸ì€ ì œì™¸
    if inp.usr_id:
        try:
            # ì§€ì—° ì„í¬íŠ¸: ì˜ì¡´ ìµœì†Œí™”
            from .intent_classifier import extract_slots_light
            _slots = extract_slots_light(inp.query) or {}
        except Exception:
            _slots = {}
        
        # ğŸ”¥ ë³µí•© ì§ˆë¬¸ ì²´í¬: ì™¸ë¶€ ëŒ€í•™ì´ë‚˜ ë³µì¡í•œ êµ¬ì¡°ê°€ ìˆìœ¼ë©´ ì˜¤ë²„ë¼ì´ë“œ í•˜ì§€ ì•ŠìŒ
        has_external_entity = bool(intent.external_entities)
        has_comparison = any(kw in inp.query for kw in ["ë¹„êµ", "ì°¨ì´", "ë™ì¼ì—°ë„", "ê°™ì€ í•´", "ì™€", "ê³¼", "ê·¸ë¦¬ê³ "])
        is_complex_query = intent.wants_calculation or has_external_entity or has_comparison
        
        # ë‹¨ìˆœí•œ ê°œì¸ ë°ì´í„° ì§ˆì˜ë§Œ ì˜¤ë²„ë¼ì´ë“œ
        if (not is_complex_query and 
            _slots.get("owner") == "self" and 
            _slots.get("metric") in {"cps", "lps", "vps", "score", "budget", "ìë£Œêµ¬ì…ë¹„"}):
            
            log.info("[PATH] override â†’ user_local (owner=self, metric=%s)", _slots.get("metric"))
            body, prof = local_exec.run_user_local(router, cfg, repo, inp.usr_id, inp.query, inp.overrides)
            return OrchestratorOutput(
                answer=body,
                route="local_user",
                meta={"intent": intent.dict(), "profile": prof, "override": "self_metric"}
            )
        elif is_complex_query:
            log.info("[PATH] complex query detected, skipping override (external=%s, calc=%s, comparison=%s)", 
                     has_external_entity, intent.wants_calculation, has_comparison)

    # 2) ê·¸ë˜í”„ ê²½ë¡œ ìš°ì„  (íƒœìŠ¤í¬ ìˆ˜ ê¸°ë°˜ í† í° ìŠ¤ì¼€ì¼ë§ ì ìš©)
    try:
        if AGENT_ENABLED and _should_use_graph(inp.query):
            log.info("[PATH] attempting graph route")
            # íƒœìŠ¤í¬ ìˆ˜ ë¯¸ë¦¬ ì¶”ì •í•˜ì—¬ í† í° ìŠ¤ì¼€ì¼ë§
            from .graph import plan_tasks, run_orchestrator_graph  # ì§€ì—° ì„í¬íŠ¸
            tasks_preview = plan_tasks(inp.query, inp.usr_id)
            base_max_new = int((inp.overrides or {}).get("max_new_tokens", cfg.get("generation", {}).get("max_new_tokens", 180)))
            scaled_tokens = _scale_max_tokens(base_max_new, len(tasks_preview), is_agent=False)
            ov_for_graph = dict(inp.overrides or {})
            ov_for_graph["max_new_tokens"] = scaled_tokens

            # ìŠ¤ì¼€ì¼ëœ overridesë¡œ ìƒˆ ì…ë ¥ êµ¬ì„±
            inp_for_graph = OrchestratorInput(
                query=inp.query,
                usr_id=inp.usr_id,
                conv_id=inp.conv_id,
                first_turn=inp.first_turn,
                overrides=ov_for_graph,
                headers=inp.headers,
                meta=inp.meta
            )

            body, tasks, results = run_orchestrator_graph(router, cfg, repo, inp_for_graph)
            meta = {
                "intent": intent.dict(),
                "graph": {
                    "task_count": len(tasks),
                    "executors": [t.get("executor") for t in tasks],
                }
            }
            log.info("[PATH] route=graph tasks=%d executors=%s",
                     len(tasks), ",".join(meta["graph"]["executors"]))
            return OrchestratorOutput(answer=body, route="graph", meta=meta)
        else:
            log.info("[PATH] graph route not eligible (agent_enabled=%s, should_use_graph=%s)", 
                     AGENT_ENABLED, _should_use_graph(inp.query))
    except Exception as e:
        log.warning("[GRAPH] orchestration failed â†’ fallback. reason=%s", e)

    # 3) ë‹¨ì¼ ê²½ë¡œ í´ë°±
    if intent.kind == "guest_base_chat":
        log.info("[PATH] route=guest_base_chat")
        body = local_exec.run_guest_base_chat(router, cfg, inp.query, inp.overrides)
        return OrchestratorOutput(answer=body, route="guest_base_chat", meta={"intent": intent.dict()})

    if intent.kind == "user_local":
        log.info("[PATH] route=local_user (user_data_chain)")
        body, prof = local_exec.run_user_local(router, cfg, repo, inp.usr_id, inp.query, inp.overrides)
        return OrchestratorOutput(answer=body, route="local_user", meta={"intent": intent.dict(), "profile": prof})

    if intent.kind == "base_chat":
        log.info("[PATH] route=base_chat")
        body, prof = local_exec.run_user_base_chat(router, cfg, repo, inp.usr_id, inp.conv_id or 0, inp.query, inp.overrides)
        return OrchestratorOutput(answer=body, route="base_chat", meta={"intent": intent.dict(), "profile": prof})

    # === agent_needed ===
    if not AGENT_ENABLED:
        log.info("[PATH] route=agent_needed_disabled (agent off)")
        return OrchestratorOutput(
            answer="ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!",
            route="agent_needed_disabled",
            meta={"intent": intent.dict()}
        )

    log.info("[PATH] route=agent_needed")
    try:
        payload = planner.make_agent_payload(intent, inp.query, inp.usr_id, inp.conv_id, inp.meta.get("session", {}))
        log.info("[AGENT_CALL] payload keys: %s", list(payload.keys()))
        res = agent_client.plan_and_run(payload)

        log.info("[AGENT_RES] response keys: %s", list(res.keys()) if isinstance(res, dict) else type(res).__name__)
        
        # ì—ì´ì „íŠ¸ ì‘ë‹µ ë””ë²„ê¹…
        if isinstance(res, dict):
            if "data" in res:
                log.info("[AGENT_RES] data keys: %s", list(res["data"].keys()) if isinstance(res["data"], dict) else type(res["data"]).__name__)
            if "tool_result" in res:
                log.info("[AGENT_RES] tool_result keys: %s", list(res["tool_result"].keys()) if isinstance(res["tool_result"], dict) else type(res["tool_result"]).__name__)

        # 1) RAG ìš°ì„  - ë¹ˆ ê²°ê³¼ë„ ì²˜ë¦¬
        rag = _extract_rag_blob(res)
        if rag is not None:  # matchesê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¼ë„ ì²˜ë¦¬
            matches = rag.get("matches", [])
            if matches:
                # ë§¤ì¹˜ê°€ ìˆëŠ” ê²½ìš°: ì •ìƒ í•©ì„±
                usr_name, usr_snm = ("ê²ŒìŠ¤íŠ¸", "")
                if inp.usr_id:
                    try:
                        prof = repo.get_user_profile(inp.usr_id)
                        usr_name, usr_snm = prof if prof else ("ì‚¬ìš©ì", "")
                    except Exception:
                        pass
                # ì—ì´ì „íŠ¸ ê²½ë¡œ: í† í° ì—¬ìœ ë¥¼ ë” ì¤€ë‹¤(ìµœì†Œ 320, ë³µí•© ìš”ì²­ì´ë©´ ë¹„ë¡€ ì¦ê°€)
                base_max_new = int((inp.overrides or {}).get("max_new_tokens", cfg.get("generation", {}).get("max_new_tokens", 180)))
                # RAGì—ì„  íƒœìŠ¤í¬ ìˆ˜ ì•Œê¸° ì–´ë µì§€ë§Œ ê¸´ ë‹µë³€ ëŒ€ë¹„ +2 ìœ ë‹› ê°€ì •
                scaled_tokens = _scale_max_tokens(base_max_new, num_units=3, is_agent=True)
                ov2 = dict(inp.overrides or {})
                ov2["max_new_tokens"] = scaled_tokens
                answer = _synthesize_from_rag(router, cfg, inp.query, rag, ov2, usr_name=usr_name, usr_snm=usr_snm)
                log.info("[AGENT_SUCCESS] RAG synthesis completed, answer length: %d", len(answer))
                return OrchestratorOutput(answer=answer, route="agent_rag", meta={"intent": intent.dict(), "agent_raw": res})
            else:
                # ê²€ìƒ‰í–ˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                log.info("[AGENT_RAG] No matches found in RAG result")
                answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                return OrchestratorOutput(answer=answer, route="agent_rag_empty", meta={"intent": intent.dict(), "agent_raw": res})

        # 2) final_data (Oracle ê²°ê³¼ ë“±)
        final_data = _extract_final_data(res)
        if final_data:
            log.info("[AGENT_SUCCESS] Found final_data: %s", list(final_data.keys()))
            
            # Oracle ëŒ€í•™ ë°ì´í„° ê²°ê³¼ í¬ë§·íŒ…
            if "university" in final_data and "value" in final_data:
                univ = final_data.get("university", "")
                year = final_data.get("year", "")
                metric = final_data.get("metric_label", "ì§€í‘œ")
                value = final_data.get("value")
                
                if value is not None:
                    answer = f"{year}ë…„ë„ {univ}ì˜ {metric}ëŠ” {value}ì…ë‹ˆë‹¤."
                else:
                    answer = f"{year}ë…„ë„ {univ}ì˜ {metric} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                return OrchestratorOutput(answer=answer, route="agent_oracle", meta={"intent": intent.dict(), "agent_raw": res})
            
            # ê¸°íƒ€ ê³„ì‚°í˜• ê²°ê³¼
            numeric_keys = any(k in final_data for k in ("user_value", "benchmark", "diff", "ratio"))
            if numeric_keys:
                unit = final_data.get("unit", "")
                txt = []
                if "user_value" in final_data: txt.append(f"ì‚¬ìš©ì ê°’: {final_data['user_value']}{unit}")
                if "benchmark" in final_data:  txt.append(f"ë¹„êµ ê¸°ì¤€: {final_data['benchmark']}{unit}")
                if "diff" in final_data:       txt.append(f"ì°¨ì´: {final_data['diff']}{unit}")
                if "ratio" in final_data:      txt.append(f"ë¹„ìœ¨: {final_data['ratio']:.4f}")
                answer = "\n".join(txt) if txt else "ê³„ì‚° ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."
                return OrchestratorOutput(answer=answer, route="agent_calc", meta={"intent": intent.dict(), "agent_raw": res})

        # 3) ì—ì´ì „íŠ¸ê°€ ì§ì ‘ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì¤€ ê²½ìš°
        text_response = _extract_text_response(res)
        if text_response:
            log.info("[AGENT_SUCCESS] Found text response, length: %d", len(text_response))
            return OrchestratorOutput(answer=text_response, route="agent_text", meta={"intent": intent.dict(), "agent_raw": res})

        # 4) ì—ëŸ¬ ì‘ë‹µ ì²˜ë¦¬
        if isinstance(res, dict) and not res.get("ok", True):
            error_msg = res.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            log.warning("[AGENT_ERROR] Agent returned error: %s", error_msg)
            return OrchestratorOutput(answer=f"ì£„ì†¡í•©ë‹ˆë‹¤. {error_msg}", route="agent_error", meta={"intent": intent.dict(), "agent_raw": res})

        # 5) ê¸°íƒ€ í´ë°±
        log.warning("[AGENT_FALLBACK] No usable response found in agent result")
        log.debug("[AGENT_FALLBACK] Full response: %s", res)
        return OrchestratorOutput(answer="ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", route="agent", meta={"intent": intent.dict(), "agent_raw": res})

    except Exception as e:
        log.exception("[AGENT_ERROR] Agent call failed: %s", e)
        return OrchestratorOutput(
            answer="ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!",
            route="agent_call_failed",
            meta={"intent": intent.dict(), "error": str(e)}
        )
# 공통
LLM_BACKEND=gguf          # gguf | hf
HUGGINGFACE_TOKEN=
HF_CACHE_DIR=services/llm_service/huggingface

# GGUF 모드 (llama.cpp)
HF_MODEL_ID=QuantFactory/Llama-3-Ko-8B-Instruct-GGUF
HF_GGUF_FILENAME=Llama-3-Ko-8B-Instruct.Q4_K_M.gguf
LLM_CTX_SIZE=4096
LLM_THREADS=8             # CPU 스레드(물리코어 근처로)
LLM_N_GPU_LAYERS=0        # CPU-only (GPU 없으면 0)

# 생성 기본값
GEN_MAX_NEW_TOKENS=512
GEN_TEMPERATURE=0.7
GEN_TOP_P=0.9


SYSTEM_PROMPT=당신은 대한민국의 대학교 별 인프라에 대한 예측서비스인 Libra 홈페이지의 도우미 리브라봇 입니다. \n
질문에 대해 최대 2줄 및 친절하고 깔끔한 질의응답을 할 줄 알며, 모든 말 끝에 냥! 을 붙입니다. \n
